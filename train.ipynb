{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309fb3af-9ca2-471b-8e1b-a7d5ab4cc468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /root/autodl-tmp\n",
      "Changed working directory to: /root/autodl-tmp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 打印当前工作目录\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# 更改当前工作目录（如果必要）\n",
    "new_dir = '/root/autodl-tmp/'\n",
    "os.chdir(new_dir)\n",
    "print(\"Changed working directory to:\", os.getcwd())\n",
    "\n",
    "# 确保当前目录在系统路径中\n",
    "if new_dir not in sys.path:\n",
    "    sys.path.append(new_dir)\n",
    "\n",
    "# 清除之前的导入缓存\n",
    "if 'myReader' in sys.modules:\n",
    "    del sys.modules['myReader']\n",
    "\n",
    "# 尝试导入 convert_example 函数\n",
    "from myReader import get_dataLoader\n",
    "\n",
    "# # 测试函数\n",
    "# convert_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a31d45-720e-4b56-8c97-c333969bab8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python3\n",
    "\"\"\"\n",
    "==== No Bugs in code, just some Random Unexpected FEATURES ====\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐│\n",
    "││Esc│!1 │@2 │#3 │$4 │%5 │^6 │&7 │*8 │(9 │)0 │_- │+= │|\\ │`~ ││\n",
    "│├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴───┤│\n",
    "││ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{[ │}] │ BS  ││\n",
    "│├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤│\n",
    "││ Ctrl │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\" '│ Enter  ││\n",
    "│├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────┬───┤│\n",
    "││ Shift  │ Z │ X │ C │ V │ B │ N │ M │< ,│> .│? /│Shift │Fn ││\n",
    "│└─────┬──┴┬──┴──┬┴───┴───┴───┴───┴───┴──┬┴───┴┬──┴┬─────┴───┘│\n",
    "│      │Fn │ Alt │         Space         │ Alt │Win│   HHKB   │\n",
    "│      └───┴─────┴───────────────────────┴─────┴───┘          │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "使用T5进行中文问答任务训练，数据集使用百度开源中文问答数据集。\n",
    "\n",
    "Author: pankeyu\n",
    "Date: 2023/01/04\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_scheduler, AdamW\n",
    "from myReader import get_dataLoader,DuReaderQG\n",
    "from bleu_metrics import BLEU\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_id = 0  \n",
    "    device = torch.device(f\"cuda:{device_id}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_checkpoint = 'uer/t5-base-chinese-cluecorpussmall'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.eos_token = tokenizer.sep_token                               \n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint) \n",
    "model.to(device)\n",
    "# model.load_state_dict(\n",
    "#     torch.load('checkpoints2/epoch_10_valid_rouge_0.0976_model_weights.bin', map_location=device)\n",
    "# )\n",
    "train_data = DuReaderQG('data/DuReaderQG/train.json')\n",
    "valid_data = DuReaderQG('data/DuReaderQG/dev.json')\n",
    "train_dataloader = get_dataLoader(train_data, model, tokenizer, 256, 32, batch_size=32, shuffle=True)\n",
    "valid_dataloader = get_dataLoader(valid_data, model, tokenizer, 256, 32, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6c5df-b928-4a0f-b144-78bb27d1c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from iTrainingLogger import iSummaryWriter\n",
    "writer = iSummaryWriter(log_path='logs/DuReaderQG2', log_name='DuReaderQG2')\n",
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        loss_avg = sum(train_losses) / len(train_losses)\n",
    "        progress_bar.set_description(f'loss: {loss_avg:>7f}')\n",
    "        progress_bar.update(1)\n",
    "        if len(train_losses) % 100 == 0:\n",
    "            writer.add_scalar('train/train_loss', loss_avg, finish_batch_num + batch)\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, epoch):\n",
    "    max_target_length = 32\n",
    "    bleu_evaluators = [BLEU(n_size=i+1) for i in range(4)]\n",
    "    preds, labels = [], []\n",
    "    model.eval()\n",
    "    a= True\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        batch_data = batch_data.to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_data = batch_data.to(device)\n",
    "            outputs = model(**batch_data)\n",
    "            loss = outputs.loss\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_target_length,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            ).cpu().numpy()\n",
    "            test_losses.append(loss.item())\n",
    "        \n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "        if a:\n",
    "            print(decoded_preds)\n",
    "            a=False\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "        for bleu_evaluator in bleu_evaluators:\n",
    "            for pred,label in zip(decoded_preds,decoded_labels):\n",
    "                bleu_evaluator.add_instance(prediction=pred.strip(), references=[label.strip()])\n",
    "    loss_avg = sum(test_losses) / len(test_losses)\n",
    "    bleu1, bleu2, bleu3, bleu4 = [bleu.compute() for bleu in bleu_evaluators]\n",
    "    writer.add_scalar('eval/eval_loss', loss_avg, epoch)\n",
    "    writer.add_scalar('eval/bleu-size-1', bleu1, epoch)\n",
    "    writer.add_scalar('eval/bleu-size-2', bleu2, epoch)\n",
    "    writer.add_scalar('eval/bleu-size-3', bleu3, epoch)\n",
    "    writer.add_scalar('eval/bleu-size-4', bleu4, epoch)\n",
    "    writer.record()\n",
    "    return bleu4    \n",
    "learning_rate = 5e-5\n",
    "epoch_num = 50\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
    "# optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=200,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "best_bleu4 = 0.\n",
    "test_loop(valid_dataloader, model, 0)\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1)\n",
    "    bleu4 = test_loop(valid_dataloader, model, t+1)\n",
    "    print(bleu4)\n",
    "    if bleu4 > best_bleu4:\n",
    "        best_bleu4 = bleu4\n",
    "        cur_save_dir = \"model_best2\"\n",
    "        if not os.path.exists(cur_save_dir):\n",
    "            os.makedirs(cur_save_dir)\n",
    "        model.save_pretrained(os.path.join(cur_save_dir))\n",
    "        tokenizer.save_pretrained(os.path.join(cur_save_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
